{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45cab84",
   "metadata": {},
   "source": [
    "# DataGrab\n",
    "\n",
    "Author: Bobby Schulz, schu3119@umn.edu || Last Updated: May 30, 2024\n",
    "\n",
    "### Function\n",
    "Grab data from GEMS Sensing database based on specified values of project, node id, and timeframe.\n",
    "\n",
    "Returns results as a [pickle](https://docs.python.org/3/library/pickle.html), a CSV, or xlsx.\n",
    "\n",
    "### Reqirements \n",
    "1. You must have valid credentials to access the GEMS Sensing database. If you do not already have credentials, email Bryan Runck (runck014@umn.edu) to get access. \n",
    "2. You must be connected to eduroam at a UMN campus **OR** be connected to a UMN network via [VPN](https://it.umn.edu/services-technologies/virtual-private-network-vpn) \n",
    "\n",
    "Acnowledgements: Based on work by Bryan Runck regarding data access "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9ea4d",
   "metadata": {},
   "source": [
    "#### Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e72eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pkg_resources\n",
    "from sqlalchemy import create_engine # engine to access database\n",
    "import pandas as pd # used to store and manipulate the data\n",
    "import os # needed for basic IO\n",
    "import json # needed for parsing of json info\n",
    "from datetime import datetime # used to handle date time information for parsing\n",
    "import time # used to keep track of current time for measuring execution time\n",
    "# import numpy as np # used for basic maths\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(dir(create_engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685db554",
   "metadata": {},
   "source": [
    "### Access credential file\n",
    "\n",
    "A credential file (`credentials.json`) is required in the same working directory that this notebook is located. The file must be laid out in the defined manor. See example in [NotActualCredentials.json](./NotActualCredentials.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ebe684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - Credential info imported from file\n"
     ]
    }
   ],
   "source": [
    "# Define the file path; default assumes same directory as this notebook\n",
    "file_path = \"credentials.json\"\n",
    "\n",
    "if os.path.isfile(file_path):\n",
    "    #If file exists, open the file for reading\n",
    "    with open(file_path, \"r\") as file:\n",
    "        credentials = json.load(file)\n",
    "    # Set Username and Password\n",
    "    try:\n",
    "        username = credentials['db_username']\n",
    "        password = credentials['db_password']\n",
    "        host = credentials['host']\n",
    "        port = credentials['port']\n",
    "        db = credentials['db']\n",
    "    except:\n",
    "        print(\"ERROR: One or more of the expected values is missing!\")\n",
    "        print(\"\\tCheck your credential file for formatting and presance of db_username, db_password, host, port, and db\")\n",
    "else:\n",
    "    print(\"ERROR: No credentials file found!\")\n",
    "    print(\"\\tPlease check location and existance of credentials.json\")\n",
    "\n",
    "print(\"DONE - Credential info imported from file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda8f99",
   "metadata": {},
   "source": [
    "#### Create postgresql engine \n",
    "Create engine for accessing database using the credential info previously imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd41fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{db}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf840c",
   "metadata": {},
   "source": [
    "### Define node names, projects, and time frames\n",
    "In the following cell the user must define the node ids of the desired nodes, along with the projects where we expect to find them, and the time frames that data should be returned.\n",
    "\n",
    "**Example input:** \n",
    "```\n",
    "node_ids = \"('INT_GEMS_2', 'GEMS_6')\"\n",
    "projects = {'eroc', 'stellenbosch')\"\n",
    "timeStart = '2023-08-16 12:30:00'\n",
    "timeStop = '2024-03-01 16:00:00;\n",
    "```\n",
    "\n",
    "**Note: Program will search for ALL node ids in ALL projects listed. As long as the node id exists in one of those projects, it will be found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39f083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = \"('MET1_MAES')\"\n",
    "projects = {'eroc'}\n",
    "timeStart = \"2023-08-16\"\n",
    "timeStop = \"2024-03-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e51719",
   "metadata": {},
   "source": [
    "### Execute data grab based on user input\n",
    "\n",
    "#### Please be patient! This may take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edeac633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin SQL Query - Please be patient, this may take some time\n",
      "\n",
      "             Project          Time [s]  \n",
      "----------------------------------------\n",
      "                eroc           111  \n",
      "\n",
      "Done\n",
      "                 time      value                   node_id           measure  \\\n",
      "0 2023-08-16 00:10:54  70.906067  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "1 2023-08-16 00:28:48  71.275330  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "2 2023-08-16 00:44:02  72.145081  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "3 2023-08-16 00:59:17  72.673035  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "4 2023-08-16 01:14:32  73.196411  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "5 2023-08-16 01:32:21  73.210144  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "6 2023-08-16 01:47:42  73.022461  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "7 2023-08-16 02:18:26  72.926331  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "8 2023-08-16 02:03:04  73.025513  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "9 2023-08-16 03:09:43  72.682190  e00fce68055fc955f7d19b4a  SHTC3.0.HUMIDITY   \n",
      "\n",
      "  display_name  \n",
      "0    MET1_MAES  \n",
      "1    MET1_MAES  \n",
      "2    MET1_MAES  \n",
      "3    MET1_MAES  \n",
      "4    MET1_MAES  \n",
      "5    MET1_MAES  \n",
      "6    MET1_MAES  \n",
      "7    MET1_MAES  \n",
      "8    MET1_MAES  \n",
      "9    MET1_MAES  \n"
     ]
    }
   ],
   "source": [
    "#Multi-Node, Multi-Project Query - GEMS\n",
    "# get data by passing a query string and database engine to pandas read_sql\n",
    "\n",
    "gemsData = pd.DataFrame() #Make empty dataframe to hold all the results\n",
    "print(\"Begin SQL Query - Please be patient, this may take some time\\n\")\n",
    "print('{:>20s}{:^10s}{:<10s}'.format('Project', '', 'Time [s]'))\n",
    "print('-'*40)\n",
    "for proj in projects:\n",
    "    query = \"SELECT * FROM \" +  proj + \".data WHERE display_name in \" + node_ids + \" AND \\\"time\\\" > '\" + timeStart + \"' AND \\\"time\\\" < '\" + timeStop + \"'\" #Concatonate values to make call to specific project and from your custom list of nodes\n",
    "# query = \"SELECT * FROM eroc.data LIMIT 1000\"\n",
    "    print('{:>20s}{:^10s}'.format(proj, ''), end =\" \") #Print project name and blank space, but don't print newline so we can print time on same line when done\n",
    "    start = time.time() #Keep track of how long execute takes\n",
    "    gemsData = pd.concat([gemsData, pd.read_sql(query, engine)]) #Concatonate data together so you get one dataframe at end\n",
    "    end = time.time()\n",
    "    print('{:<5.0f}'.format((end-start)))\n",
    "print(\"\\nDone\")\n",
    "\n",
    "nodeVals = node_ids[1:-1].split(',')\n",
    "nodeVals = [s.strip(\"'\") for s in nodeVals] #Extract list of node names from string of node names\n",
    "\n",
    "missingNodes = set(nodeVals).difference(set(gemsData['display_name'].unique()))\n",
    "if len(missingNodes) > 0: #Only print out if there any missing nodes\n",
    "    print(\"\\n\\nMissing Nodes:\") \n",
    "    for node in missingNodes: #Print out list of any missing nodes\n",
    "        print(\"\\t\", node)\n",
    "        \n",
    "print(gemsData.head(10)) #Print out sample of data\n",
    "\n",
    "print(\"Done! Query completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adce90",
   "metadata": {},
   "source": [
    "### Save Data\n",
    "Proceed below to save the data in one of various formats\n",
    "\n",
    "- CSV\n",
    "    - The most generalizeable form of data storage, but not as efficient as Pickle for reading from, etc. Good for universal access.\n",
    "- XLSX\n",
    "    - Excel proprietary format. Helpful for those who are forced to work within Excel, but not for much else. \n",
    "- Pickle\n",
    "    - File type used by Python to store large amounts of data. This is helpful if you want to load this data into another Python enviroment and analyize it. \n",
    "\n",
    "| Format | Ease of Use (Novice) | Ease of Use (Analyist) | Modularity | File Size | Write Time | Read Time |\n",
    "| ------ | -------------------- | ---------------------- | ---------- | --------- | ---------- | --------- |\n",
    "| CSV | Good | Good | Best | Worst | Good | Good |\n",
    "| XLSX | Best | Poor | Poor | Best | WORST | WORST |\n",
    "| Pickle | Worst | Best | Worst | Ok | Best | Best |\n",
    "\n",
    "Example:\n",
    "\n",
    "269k records (one node, about 6 months)\n",
    "\n",
    "| Format | Write Time | Read Time | File Size | \n",
    "| ------ | ---------- | --------- | --------- |\n",
    "| CSV | 1.18s | 240ms | 21.6 MB |\n",
    "| XLSX | 21s | 17s | 7.2 MB |\n",
    "| Pickle | 210ms | 110ms | 19.7 MB | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "737ffb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717092561.3715267\n",
      "1717092562.5549514\n",
      "1717092562.766386\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"GEMS_Data\"): #If there is not already a data folder, make one\n",
    "    os.mkdir(\"GEMS_Data\") #Make a folder to keep data in for saving to prevent clutter\n",
    "timeStr = str(datetime.now().replace(microsecond=0).isoformat()) #Grab ISO 8601 format YYYY-mm-ddTHH:MM:SS\n",
    "timeStr = timeStr.replace('-', '') #Strip out hypens for file naming\n",
    "timeStr = timeStr.replace(':', '') #Strip out colons for file naming\n",
    "\n",
    "# Comment out the following to ommit any save options\n",
    "gemsData.to_csv('GEMS_Data/Data_' + timeStr + '.csv', index=None) #CSV\n",
    "gemsData.to_excel('GEMS_Data/Data_' + timeStr + '.xlsx', index=None) #XLSX\n",
    "gemsData.to_pickle('GEMS_Data/Data_' + timeStr + '.pkl') #PICKLE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
